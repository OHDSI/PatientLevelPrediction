% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/LearningCurve.R
\name{createLearningCurve}
\alias{createLearningCurve}
\title{learningCurve - Create a learning curve}
\usage{
createLearningCurve(population, plpData, modelSettings, testSplit = "time",
  testFraction = 0.25, trainFractions = c(0.25, 0.5, 0.75),
  splitSeed = NULL, nfold = 3, indexes = NULL, save = NULL,
  saveModel = T, verbosity = futile.logger::INFO, timeStamp = FALSE,
  analysisId = NULL)
}
\arguments{
\item{population}{The population created using createStudyPopulation() who will be used to develop the model}

\item{plpData}{An object of type \code{plpData} - the patient level prediction
data extracted from the CDM.}

\item{modelSettings}{An object of class \code{modelSettings} created using one of the function:
\itemize{
\item{logisticRegressionModel()}{ A lasso logistic regression model}
\item{GBMclassifier()}{ A gradient boosting machine}
\item{RFclassifier()}{ A random forest model}
\item{GLMclassifier ()}{ A generalised linear model}
\item{KNNclassifier()}{ A KNN model}
}}

\item{testSplit}{Either 'person' or 'time' specifying the type of evaluation used.
'time' find the date where testFraction of patients had an index after the date and assigns patients with an index prior to this date into the training set and post the date into the test set
'person' splits the data into test (1-testFraction of the data) and
train (validationFraction of the data) sets.  The split is stratified by the class label.}

\item{testFraction}{The fraction of the data to be used as the test set in the patient
split evaluation.}

\item{trainFractions}{A list of trainFractions to try}

\item{splitSeed}{The seed used to split the test/train set when using a person type testSplit}

\item{nfold}{The number of folds used in the cross validation (default 3)}

\item{indexes}{A dataframe containing a rowId and index column where the index value of -1 means in the test set, and positive integer represents the cross validation fold (default is NULL)}

\item{save}{The path to the directory where the models will be saved (if NULL uses working directory)}

\item{saveModel}{Binary indicating whether to save the model once it is trained (default is T)}

\item{verbosity}{Sets the level of the verbosity. If the log level is at or higher in priority than the logger threshold, a message will print. The levels are:
\itemize{
\item{DEBUG}{Highest verbosity showing all debug statements}
\item{TRACE}{Showing information about start and end of steps}
\item{INFO}{Show informative information (Default)}
\item{WARN}{Show warning messages}
\item{ERROR}{Show error messages}
\item{FATAL}{Be silent except for fatal errors}
}}

\item{timeStamp}{If TRUE a timestamp will be added to each logging statement. Automatically switched on for TRACE level.}

\item{analysisId}{Identifier for the analysis. It is used to create, e.g., the result folder. Default is a timestamp.}
}
\value{
An object containing the model or location where the model is save, the data selection settings, the preprocessing
and training settings as well as various performance measures obtained by the model.

\item{predict}{A function that can be applied to new data to apply the trained model and make predictions}
\item{model}{A list of class \code{plpModel} containing the model, training metrics and model metadata}
\item{prediction}{A dataframe containing the prediction for each person in the test set }
\item{evalType}{The type of evaluation that was performed ('person' or 'time')}
\item{performanceTest}{A list detailing the size of the test sets}
\item{performanceTrain}{A list detailing the size of the train sets}
\item{time}{The complete time taken to do the model framework}
}
\description{
#'
}
\details{

}
