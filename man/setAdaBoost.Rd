% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/SklearnClassifierSettings.R
\name{setAdaBoost}
\alias{setAdaBoost}
\title{Create setting for AdaBoost with python DecisionTreeClassifier base estimator}
\usage{
setAdaBoost(
  nEstimators = list(10, 50, 200),
  learningRate = list(1, 0.5, 0.1),
  algorithm = list("SAMME.R"),
  seed = sample(1e+06, 1)
)
}
\arguments{
\item{nEstimators}{(list) The maximum number of estimators at which boosting is terminated. In case of perfect fit, the learning procedure is stopped early.}

\item{learningRate}{(list) Weight applied to each classifier at each boosting iteration. A higher learning rate increases the contribution of each classifier. There is a trade-off between the learningRate and nEstimators parameters
There is a trade-off between learningRate and nEstimators.}

\item{algorithm}{(list) If ‘SAMME.R’ then use the SAMME.R real boosting algorithm. base_estimator must support calculation of class probabilities. If ‘SAMME’ then use the SAMME discrete boosting algorithm. The SAMME.R algorithm typically converges faster than SAMME, achieving a lower test error with fewer boosting iterations.}

\item{seed}{A seed for the model}
}
\description{
Create setting for AdaBoost with python DecisionTreeClassifier base estimator
}
\examples{
\dontrun{
model.adaBoost <- setAdaBoost(nEstimators = list(10,50,200), learningRate = list(1, 0.5, 0.1),
                              algorithm = list('SAMME.R'), seed = sample(1000000,1)
                              )
}
}
